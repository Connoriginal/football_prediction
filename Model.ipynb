{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 271,
   "id": "a25ec44e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import eplDataset as eds\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torchvision\n",
    "import torchvision.datasets as datasets\n",
    "from torchvision import transforms\n",
    "from torch.utils.data import DataLoader"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12222595",
   "metadata": {},
   "source": [
    "## Load Training Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 272,
   "id": "b8457e8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 12\n",
    "# data Transform\n",
    "trans = transforms.Compose([\n",
    "                            transforms.ToTensor(),\n",
    "#                             transforms.Normalize([0.5],[0.5]),\n",
    "                           ])\n",
    "\n",
    "train_data = eds.EplDataset(train=True,transform=trans)\n",
    "test_data = eds.EplDataset(train=False,transform=trans)\n",
    "\n",
    "train_loader = DataLoader(train_data, batch_size = batch_size, shuffle=True)\n",
    "test_loader = DataLoader(test_data,batch_size = batch_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81b3e4ae",
   "metadata": {},
   "source": [
    "## MLP Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 273,
   "id": "2763113e",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MLP(nn.Module):\n",
    "    def __init__(self, hidden_units = [512,256,128,64,32]):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.in_dim = 22 # MNIST\n",
    "        self.out_dim = 3\n",
    "        \n",
    "        self.l_layers = []\n",
    "        self.l_layers.append(nn.Linear(self.in_dim,hidden_units[0]))\n",
    "        for i in range(len(hidden_units)-1) :\n",
    "            self.l_layers.append(nn.Linear(hidden_units[i],hidden_units[i+1]))\n",
    "        self.l_layers.append(nn.Linear(hidden_units[-1],self.out_dim))\n",
    "        \n",
    "        self.l_layers = nn.ModuleList(self.l_layers)\n",
    "        \n",
    "        self.relu = nn.ReLU()\n",
    "        self.log_softmax = nn.LogSoftmax()\n",
    "        \n",
    "    def forward(self,x):\n",
    "        a = x.view(-1,self.in_dim)\n",
    "        output_list = []\n",
    "        \n",
    "        for i in range(len(self.l_layers)) :\n",
    "            z = self.l_layers[i](a)\n",
    "            output_list.append(z)\n",
    "            if i != len(self.l_layers) -1 :\n",
    "                a = self.relu(z)\n",
    "            else : \n",
    "                out = z\n",
    "                a = self.log_softmax(z)\n",
    "            output_list.append(a)\n",
    "                        \n",
    "        return out, output_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 274,
   "id": "946e89c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = MLP()\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr = 0.0001,weight_decay = 1e-5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82868196",
   "metadata": {},
   "source": [
    "## Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 279,
   "id": "113440bd",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-273-a89117153749>:30: UserWarning: Implicit dimension choice for log_softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  a = self.log_softmax(z)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1,   100] loss : 0.041239\n",
      "[1,   200] loss : 0.042485\n",
      "[2,   100] loss : 0.041827\n",
      "[2,   200] loss : 0.041271\n",
      "[3,   100] loss : 0.041520\n",
      "[3,   200] loss : 0.041662\n",
      "[4,   100] loss : 0.041644\n",
      "[4,   200] loss : 0.042238\n",
      "[5,   100] loss : 0.041451\n",
      "[5,   200] loss : 0.041249\n",
      "[6,   100] loss : 0.043085\n",
      "[6,   200] loss : 0.041777\n",
      "[7,   100] loss : 0.041818\n",
      "[7,   200] loss : 0.043350\n",
      "[8,   100] loss : 0.042308\n",
      "[8,   200] loss : 0.041583\n",
      "[9,   100] loss : 0.041793\n",
      "[9,   200] loss : 0.040927\n",
      "[10,   100] loss : 0.041029\n",
      "[10,   200] loss : 0.041648\n",
      "[11,   100] loss : 0.040491\n",
      "[11,   200] loss : 0.042656\n",
      "[12,   100] loss : 0.042033\n",
      "[12,   200] loss : 0.041807\n",
      "[13,   100] loss : 0.041347\n",
      "[13,   200] loss : 0.041447\n",
      "[14,   100] loss : 0.040919\n",
      "[14,   200] loss : 0.041121\n",
      "[15,   100] loss : 0.042285\n",
      "[15,   200] loss : 0.041246\n",
      "[16,   100] loss : 0.041792\n",
      "[16,   200] loss : 0.041596\n",
      "[17,   100] loss : 0.040784\n",
      "[17,   200] loss : 0.042972\n",
      "[18,   100] loss : 0.042995\n",
      "[18,   200] loss : 0.040528\n",
      "[19,   100] loss : 0.040920\n",
      "[19,   200] loss : 0.042039\n",
      "[20,   100] loss : 0.041473\n",
      "[20,   200] loss : 0.042111\n",
      "[21,   100] loss : 0.041481\n",
      "[21,   200] loss : 0.045442\n",
      "[22,   100] loss : 0.041865\n",
      "[22,   200] loss : 0.043939\n",
      "[23,   100] loss : 0.041403\n",
      "[23,   200] loss : 0.042335\n",
      "[24,   100] loss : 0.043598\n",
      "[24,   200] loss : 0.041310\n",
      "[25,   100] loss : 0.042575\n",
      "[25,   200] loss : 0.040483\n",
      "[26,   100] loss : 0.041676\n",
      "[26,   200] loss : 0.040847\n",
      "[27,   100] loss : 0.041030\n",
      "[27,   200] loss : 0.041459\n",
      "[28,   100] loss : 0.041230\n",
      "[28,   200] loss : 0.041686\n",
      "[29,   100] loss : 0.041516\n",
      "[29,   200] loss : 0.041218\n",
      "[30,   100] loss : 0.041218\n",
      "[30,   200] loss : 0.041357\n",
      "[31,   100] loss : 0.041400\n",
      "[31,   200] loss : 0.041784\n",
      "[32,   100] loss : 0.041672\n",
      "[32,   200] loss : 0.041255\n",
      "[33,   100] loss : 0.040639\n",
      "[33,   200] loss : 0.042747\n",
      "[34,   100] loss : 0.039438\n",
      "[34,   200] loss : 0.042522\n",
      "[35,   100] loss : 0.041633\n",
      "[35,   200] loss : 0.040873\n",
      "[36,   100] loss : 0.041209\n",
      "[36,   200] loss : 0.042760\n",
      "[37,   100] loss : 0.041567\n",
      "[37,   200] loss : 0.042008\n",
      "[38,   100] loss : 0.042022\n",
      "[38,   200] loss : 0.041606\n",
      "[39,   100] loss : 0.042177\n",
      "[39,   200] loss : 0.040330\n",
      "[40,   100] loss : 0.041723\n",
      "[40,   200] loss : 0.041468\n",
      "[41,   100] loss : 0.041538\n",
      "[41,   200] loss : 0.041379\n",
      "[42,   100] loss : 0.042318\n",
      "[42,   200] loss : 0.040724\n",
      "[43,   100] loss : 0.041232\n",
      "[43,   200] loss : 0.041321\n",
      "[44,   100] loss : 0.041500\n",
      "[44,   200] loss : 0.040875\n",
      "[45,   100] loss : 0.044071\n",
      "[45,   200] loss : 0.042950\n",
      "[46,   100] loss : 0.042150\n",
      "[46,   200] loss : 0.041931\n",
      "[47,   100] loss : 0.040796\n",
      "[47,   200] loss : 0.041848\n",
      "[48,   100] loss : 0.041510\n",
      "[48,   200] loss : 0.041128\n",
      "[49,   100] loss : 0.041118\n",
      "[49,   200] loss : 0.041747\n",
      "[50,   100] loss : 0.041807\n",
      "[50,   200] loss : 0.040905\n",
      "[51,   100] loss : 0.040812\n",
      "[51,   200] loss : 0.042269\n",
      "[52,   100] loss : 0.040934\n",
      "[52,   200] loss : 0.040758\n",
      "[53,   100] loss : 0.041999\n",
      "[53,   200] loss : 0.040368\n",
      "[54,   100] loss : 0.041821\n",
      "[54,   200] loss : 0.040825\n",
      "[55,   100] loss : 0.040100\n",
      "[55,   200] loss : 0.042300\n",
      "[56,   100] loss : 0.039187\n",
      "[56,   200] loss : 0.042466\n",
      "[57,   100] loss : 0.041395\n",
      "[57,   200] loss : 0.041692\n",
      "[58,   100] loss : 0.041132\n",
      "[58,   200] loss : 0.041814\n",
      "[59,   100] loss : 0.040917\n",
      "[59,   200] loss : 0.042268\n",
      "[60,   100] loss : 0.041198\n",
      "[60,   200] loss : 0.040787\n",
      "[61,   100] loss : 0.041007\n",
      "[61,   200] loss : 0.041242\n",
      "[62,   100] loss : 0.042552\n",
      "[62,   200] loss : 0.040499\n",
      "[63,   100] loss : 0.041320\n",
      "[63,   200] loss : 0.042073\n",
      "[64,   100] loss : 0.040858\n",
      "[64,   200] loss : 0.043915\n",
      "[65,   100] loss : 0.043821\n",
      "[65,   200] loss : 0.041432\n",
      "[66,   100] loss : 0.041371\n",
      "[66,   200] loss : 0.042200\n",
      "[67,   100] loss : 0.040400\n",
      "[67,   200] loss : 0.041072\n",
      "[68,   100] loss : 0.040584\n",
      "[68,   200] loss : 0.041278\n",
      "[69,   100] loss : 0.041224\n",
      "[69,   200] loss : 0.041431\n",
      "[70,   100] loss : 0.041401\n",
      "[70,   200] loss : 0.041245\n",
      "[71,   100] loss : 0.042001\n",
      "[71,   200] loss : 0.041117\n",
      "[72,   100] loss : 0.040167\n",
      "[72,   200] loss : 0.040894\n",
      "[73,   100] loss : 0.041371\n",
      "[73,   200] loss : 0.040276\n",
      "[74,   100] loss : 0.040535\n",
      "[74,   200] loss : 0.041301\n",
      "[75,   100] loss : 0.040032\n",
      "[75,   200] loss : 0.041873\n",
      "[76,   100] loss : 0.041559\n",
      "[76,   200] loss : 0.041998\n",
      "[77,   100] loss : 0.041665\n",
      "[77,   200] loss : 0.039834\n",
      "[78,   100] loss : 0.042038\n",
      "[78,   200] loss : 0.041052\n",
      "[79,   100] loss : 0.041019\n",
      "[79,   200] loss : 0.040423\n",
      "[80,   100] loss : 0.040677\n",
      "[80,   200] loss : 0.040958\n",
      "[81,   100] loss : 0.040751\n",
      "[81,   200] loss : 0.040700\n",
      "[82,   100] loss : 0.039773\n",
      "[82,   200] loss : 0.042262\n",
      "[83,   100] loss : 0.040568\n",
      "[83,   200] loss : 0.041541\n",
      "[84,   100] loss : 0.039200\n",
      "[84,   200] loss : 0.041327\n",
      "[85,   100] loss : 0.041226\n",
      "[85,   200] loss : 0.040752\n",
      "[86,   100] loss : 0.039103\n",
      "[86,   200] loss : 0.041971\n",
      "[87,   100] loss : 0.039527\n",
      "[87,   200] loss : 0.041368\n",
      "[88,   100] loss : 0.041637\n",
      "[88,   200] loss : 0.040722\n",
      "[89,   100] loss : 0.040883\n",
      "[89,   200] loss : 0.042684\n",
      "[90,   100] loss : 0.040127\n",
      "[90,   200] loss : 0.041450\n",
      "[91,   100] loss : 0.039240\n",
      "[91,   200] loss : 0.041407\n",
      "[92,   100] loss : 0.041102\n",
      "[92,   200] loss : 0.040718\n",
      "[93,   100] loss : 0.040042\n",
      "[93,   200] loss : 0.040537\n",
      "[94,   100] loss : 0.041442\n",
      "[94,   200] loss : 0.040524\n",
      "[95,   100] loss : 0.040369\n",
      "[95,   200] loss : 0.040219\n",
      "[96,   100] loss : 0.039659\n",
      "[96,   200] loss : 0.041328\n",
      "[97,   100] loss : 0.040489\n",
      "[97,   200] loss : 0.041217\n",
      "[98,   100] loss : 0.040237\n",
      "[98,   200] loss : 0.040570\n",
      "[99,   100] loss : 0.041221\n",
      "[99,   200] loss : 0.040210\n",
      "[100,   100] loss : 0.040145\n",
      "[100,   200] loss : 0.041060\n",
      "[101,   100] loss : 0.040232\n",
      "[101,   200] loss : 0.041234\n",
      "[102,   100] loss : 0.040395\n",
      "[102,   200] loss : 0.039545\n",
      "[103,   100] loss : 0.039888\n",
      "[103,   200] loss : 0.041328\n",
      "[104,   100] loss : 0.042017\n",
      "[104,   200] loss : 0.039990\n",
      "[105,   100] loss : 0.039661\n",
      "[105,   200] loss : 0.040633\n",
      "[106,   100] loss : 0.040580\n",
      "[106,   200] loss : 0.042292\n",
      "[107,   100] loss : 0.041816\n",
      "[107,   200] loss : 0.043425\n",
      "[108,   100] loss : 0.041132\n",
      "[108,   200] loss : 0.040812\n",
      "[109,   100] loss : 0.040101\n",
      "[109,   200] loss : 0.041524\n",
      "[110,   100] loss : 0.039579\n",
      "[110,   200] loss : 0.040699\n",
      "[111,   100] loss : 0.039979\n",
      "[111,   200] loss : 0.040762\n",
      "[112,   100] loss : 0.040192\n",
      "[112,   200] loss : 0.040705\n",
      "[113,   100] loss : 0.040349\n",
      "[113,   200] loss : 0.040687\n",
      "[114,   100] loss : 0.040423\n",
      "[114,   200] loss : 0.040226\n",
      "[115,   100] loss : 0.040499\n",
      "[115,   200] loss : 0.040512\n",
      "[116,   100] loss : 0.041474\n",
      "[116,   200] loss : 0.038897\n",
      "[117,   100] loss : 0.040609\n",
      "[117,   200] loss : 0.040094\n",
      "[118,   100] loss : 0.040850\n",
      "[118,   200] loss : 0.041087\n",
      "[119,   100] loss : 0.040964\n",
      "[119,   200] loss : 0.040239\n",
      "[120,   100] loss : 0.040573\n",
      "[120,   200] loss : 0.042177\n",
      "[121,   100] loss : 0.042556\n",
      "[121,   200] loss : 0.041877\n",
      "[122,   100] loss : 0.039108\n",
      "[122,   200] loss : 0.041309\n",
      "[123,   100] loss : 0.040775\n",
      "[123,   200] loss : 0.040176\n",
      "[124,   100] loss : 0.040155\n",
      "[124,   200] loss : 0.040576\n",
      "[125,   100] loss : 0.041048\n",
      "[125,   200] loss : 0.038814\n",
      "[126,   100] loss : 0.039340\n",
      "[126,   200] loss : 0.040722\n",
      "[127,   100] loss : 0.039976\n",
      "[127,   200] loss : 0.040594\n",
      "[128,   100] loss : 0.039644\n",
      "[128,   200] loss : 0.039755\n",
      "[129,   100] loss : 0.040616\n",
      "[129,   200] loss : 0.040164\n",
      "[130,   100] loss : 0.039251\n",
      "[130,   200] loss : 0.040324\n",
      "[131,   100] loss : 0.040137\n",
      "[131,   200] loss : 0.040206\n",
      "[132,   100] loss : 0.039693\n",
      "[132,   200] loss : 0.040634\n",
      "[133,   100] loss : 0.039481\n",
      "[133,   200] loss : 0.040645\n",
      "[134,   100] loss : 0.040252\n",
      "[134,   200] loss : 0.040754\n",
      "[135,   100] loss : 0.042971\n",
      "[135,   200] loss : 0.041969\n",
      "[136,   100] loss : 0.040916\n",
      "[136,   200] loss : 0.042725\n",
      "[137,   100] loss : 0.040688\n",
      "[137,   200] loss : 0.039289\n",
      "[138,   100] loss : 0.039611\n",
      "[138,   200] loss : 0.040000\n",
      "[139,   100] loss : 0.040133\n",
      "[139,   200] loss : 0.039669\n",
      "[140,   100] loss : 0.040897\n",
      "[140,   200] loss : 0.039242\n",
      "[141,   100] loss : 0.039855\n",
      "[141,   200] loss : 0.039586\n",
      "[142,   100] loss : 0.040761\n",
      "[142,   200] loss : 0.039256\n",
      "[143,   100] loss : 0.040312\n",
      "[143,   200] loss : 0.039849\n",
      "[144,   100] loss : 0.040910\n",
      "[144,   200] loss : 0.039135\n",
      "[145,   100] loss : 0.039078\n",
      "[145,   200] loss : 0.040261\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[146,   100] loss : 0.039899\n",
      "[146,   200] loss : 0.040654\n",
      "[147,   100] loss : 0.039280\n",
      "[147,   200] loss : 0.040938\n",
      "[148,   100] loss : 0.039208\n",
      "[148,   200] loss : 0.041221\n",
      "[149,   100] loss : 0.039834\n",
      "[149,   200] loss : 0.040039\n",
      "[150,   100] loss : 0.038946\n",
      "[150,   200] loss : 0.041099\n",
      "[151,   100] loss : 0.039174\n",
      "[151,   200] loss : 0.040880\n",
      "[152,   100] loss : 0.040081\n",
      "[152,   200] loss : 0.040439\n",
      "[153,   100] loss : 0.039884\n",
      "[153,   200] loss : 0.040409\n",
      "[154,   100] loss : 0.039138\n",
      "[154,   200] loss : 0.040044\n",
      "[155,   100] loss : 0.040617\n",
      "[155,   200] loss : 0.039837\n",
      "[156,   100] loss : 0.040361\n",
      "[156,   200] loss : 0.043463\n",
      "[157,   100] loss : 0.040086\n",
      "[157,   200] loss : 0.041519\n",
      "[158,   100] loss : 0.038667\n",
      "[158,   200] loss : 0.041210\n",
      "[159,   100] loss : 0.040664\n",
      "[159,   200] loss : 0.038721\n",
      "[160,   100] loss : 0.040346\n",
      "[160,   200] loss : 0.039266\n",
      "[161,   100] loss : 0.039724\n",
      "[161,   200] loss : 0.039906\n",
      "[162,   100] loss : 0.040008\n",
      "[162,   200] loss : 0.040034\n",
      "[163,   100] loss : 0.038484\n",
      "[163,   200] loss : 0.040953\n",
      "[164,   100] loss : 0.039906\n",
      "[164,   200] loss : 0.040534\n",
      "[165,   100] loss : 0.041131\n",
      "[165,   200] loss : 0.038564\n",
      "[166,   100] loss : 0.039520\n",
      "[166,   200] loss : 0.038764\n",
      "[167,   100] loss : 0.039428\n",
      "[167,   200] loss : 0.039789\n",
      "[168,   100] loss : 0.039217\n",
      "[168,   200] loss : 0.040855\n",
      "[169,   100] loss : 0.040075\n",
      "[169,   200] loss : 0.039312\n",
      "[170,   100] loss : 0.042798\n",
      "[170,   200] loss : 0.039163\n",
      "[171,   100] loss : 0.041221\n",
      "[171,   200] loss : 0.039385\n",
      "[172,   100] loss : 0.040764\n",
      "[172,   200] loss : 0.038836\n",
      "[173,   100] loss : 0.040158\n",
      "[173,   200] loss : 0.038710\n",
      "[174,   100] loss : 0.039751\n",
      "[174,   200] loss : 0.038266\n",
      "[175,   100] loss : 0.038996\n",
      "[175,   200] loss : 0.040241\n",
      "[176,   100] loss : 0.040215\n",
      "[176,   200] loss : 0.040464\n",
      "[177,   100] loss : 0.038566\n",
      "[177,   200] loss : 0.040774\n",
      "[178,   100] loss : 0.040513\n",
      "[178,   200] loss : 0.038756\n",
      "[179,   100] loss : 0.039318\n",
      "[179,   200] loss : 0.038709\n",
      "[180,   100] loss : 0.039391\n",
      "[180,   200] loss : 0.039435\n",
      "[181,   100] loss : 0.039682\n",
      "[181,   200] loss : 0.038841\n",
      "[182,   100] loss : 0.039573\n",
      "[182,   200] loss : 0.039307\n",
      "[183,   100] loss : 0.038612\n",
      "[183,   200] loss : 0.039557\n",
      "[184,   100] loss : 0.039815\n",
      "[184,   200] loss : 0.040332\n",
      "[185,   100] loss : 0.038687\n",
      "[185,   200] loss : 0.040521\n",
      "[186,   100] loss : 0.039622\n",
      "[186,   200] loss : 0.039641\n",
      "[187,   100] loss : 0.044558\n",
      "[187,   200] loss : 0.040202\n",
      "[188,   100] loss : 0.040086\n",
      "[188,   200] loss : 0.039303\n",
      "[189,   100] loss : 0.039951\n",
      "[189,   200] loss : 0.039486\n",
      "[190,   100] loss : 0.039856\n",
      "[190,   200] loss : 0.039050\n",
      "[191,   100] loss : 0.039695\n",
      "[191,   200] loss : 0.038115\n",
      "[192,   100] loss : 0.039833\n",
      "[192,   200] loss : 0.038084\n",
      "[193,   100] loss : 0.038155\n",
      "[193,   200] loss : 0.040603\n",
      "[194,   100] loss : 0.038661\n",
      "[194,   200] loss : 0.039619\n",
      "[195,   100] loss : 0.039538\n",
      "[195,   200] loss : 0.038469\n",
      "[196,   100] loss : 0.038586\n",
      "[196,   200] loss : 0.039910\n",
      "[197,   100] loss : 0.039527\n",
      "[197,   200] loss : 0.039574\n",
      "[198,   100] loss : 0.038523\n",
      "[198,   200] loss : 0.039880\n",
      "[199,   100] loss : 0.039184\n",
      "[199,   200] loss : 0.038859\n",
      "[200,   100] loss : 0.039138\n",
      "[200,   200] loss : 0.039442\n",
      "[201,   100] loss : 0.038150\n",
      "[201,   200] loss : 0.040432\n",
      "[202,   100] loss : 0.039855\n",
      "[202,   200] loss : 0.038901\n",
      "[203,   100] loss : 0.040500\n",
      "[203,   200] loss : 0.038496\n",
      "[204,   100] loss : 0.038868\n",
      "[204,   200] loss : 0.040457\n",
      "[205,   100] loss : 0.043240\n",
      "[205,   200] loss : 0.039790\n",
      "[206,   100] loss : 0.039772\n",
      "[206,   200] loss : 0.038239\n",
      "[207,   100] loss : 0.039298\n",
      "[207,   200] loss : 0.038805\n",
      "[208,   100] loss : 0.039257\n",
      "[208,   200] loss : 0.039038\n",
      "[209,   100] loss : 0.039411\n",
      "[209,   200] loss : 0.038673\n",
      "[210,   100] loss : 0.038760\n",
      "[210,   200] loss : 0.039449\n",
      "[211,   100] loss : 0.038642\n",
      "[211,   200] loss : 0.038156\n",
      "[212,   100] loss : 0.038648\n",
      "[212,   200] loss : 0.039629\n",
      "[213,   100] loss : 0.038425\n",
      "[213,   200] loss : 0.040437\n",
      "[214,   100] loss : 0.039665\n",
      "[214,   200] loss : 0.038044\n",
      "[215,   100] loss : 0.040195\n",
      "[215,   200] loss : 0.037735\n",
      "[216,   100] loss : 0.039004\n",
      "[216,   200] loss : 0.038470\n",
      "[217,   100] loss : 0.040107\n",
      "[217,   200] loss : 0.038816\n",
      "[218,   100] loss : 0.038265\n",
      "[218,   200] loss : 0.040673\n",
      "[219,   100] loss : 0.038341\n",
      "[219,   200] loss : 0.040322\n",
      "[220,   100] loss : 0.038638\n",
      "[220,   200] loss : 0.038504\n",
      "[221,   100] loss : 0.040154\n",
      "[221,   200] loss : 0.037884\n",
      "[222,   100] loss : 0.038065\n",
      "[222,   200] loss : 0.040287\n",
      "[223,   100] loss : 0.040186\n",
      "[223,   200] loss : 0.038248\n",
      "[224,   100] loss : 0.040530\n",
      "[224,   200] loss : 0.039576\n",
      "[225,   100] loss : 0.039331\n",
      "[225,   200] loss : 0.038940\n",
      "[226,   100] loss : 0.037707\n",
      "[226,   200] loss : 0.039161\n",
      "[227,   100] loss : 0.039295\n",
      "[227,   200] loss : 0.039373\n",
      "[228,   100] loss : 0.038980\n",
      "[228,   200] loss : 0.039689\n",
      "[229,   100] loss : 0.039684\n",
      "[229,   200] loss : 0.039980\n",
      "[230,   100] loss : 0.039089\n",
      "[230,   200] loss : 0.038540\n",
      "[231,   100] loss : 0.038239\n",
      "[231,   200] loss : 0.039837\n",
      "[232,   100] loss : 0.037708\n",
      "[232,   200] loss : 0.038592\n",
      "[233,   100] loss : 0.038636\n",
      "[233,   200] loss : 0.038697\n",
      "[234,   100] loss : 0.037002\n",
      "[234,   200] loss : 0.040166\n",
      "[235,   100] loss : 0.038637\n",
      "[235,   200] loss : 0.039319\n",
      "[236,   100] loss : 0.037717\n",
      "[236,   200] loss : 0.039861\n",
      "[237,   100] loss : 0.038501\n",
      "[237,   200] loss : 0.039425\n",
      "[238,   100] loss : 0.038042\n",
      "[238,   200] loss : 0.039066\n",
      "[239,   100] loss : 0.038688\n",
      "[239,   200] loss : 0.038991\n",
      "[240,   100] loss : 0.038017\n",
      "[240,   200] loss : 0.038940\n",
      "[241,   100] loss : 0.038150\n",
      "[241,   200] loss : 0.038310\n",
      "[242,   100] loss : 0.038402\n",
      "[242,   200] loss : 0.039057\n",
      "[243,   100] loss : 0.039301\n",
      "[243,   200] loss : 0.039541\n",
      "[244,   100] loss : 0.038725\n",
      "[244,   200] loss : 0.042009\n",
      "[245,   100] loss : 0.044140\n",
      "[245,   200] loss : 0.039870\n",
      "[246,   100] loss : 0.038950\n",
      "[246,   200] loss : 0.039225\n",
      "[247,   100] loss : 0.038896\n",
      "[247,   200] loss : 0.039907\n",
      "[248,   100] loss : 0.038590\n",
      "[248,   200] loss : 0.037782\n",
      "[249,   100] loss : 0.038109\n",
      "[249,   200] loss : 0.038483\n",
      "[250,   100] loss : 0.037790\n",
      "[250,   200] loss : 0.038853\n",
      "[251,   100] loss : 0.038299\n",
      "[251,   200] loss : 0.038106\n",
      "[252,   100] loss : 0.038202\n",
      "[252,   200] loss : 0.038338\n",
      "[253,   100] loss : 0.038029\n",
      "[253,   200] loss : 0.039151\n",
      "[254,   100] loss : 0.038111\n",
      "[254,   200] loss : 0.038435\n",
      "[255,   100] loss : 0.039085\n",
      "[255,   200] loss : 0.037926\n",
      "[256,   100] loss : 0.037914\n",
      "[256,   200] loss : 0.038802\n",
      "[257,   100] loss : 0.037302\n",
      "[257,   200] loss : 0.040823\n",
      "[258,   100] loss : 0.038343\n",
      "[258,   200] loss : 0.038909\n",
      "[259,   100] loss : 0.037874\n",
      "[259,   200] loss : 0.038767\n",
      "[260,   100] loss : 0.037314\n",
      "[260,   200] loss : 0.039209\n",
      "[261,   100] loss : 0.038396\n",
      "[261,   200] loss : 0.039456\n",
      "[262,   100] loss : 0.039359\n",
      "[262,   200] loss : 0.037663\n",
      "[263,   100] loss : 0.040375\n",
      "[263,   200] loss : 0.037052\n",
      "[264,   100] loss : 0.039963\n",
      "[264,   200] loss : 0.037034\n",
      "[265,   100] loss : 0.037740\n",
      "[265,   200] loss : 0.038848\n",
      "[266,   100] loss : 0.038315\n",
      "[266,   200] loss : 0.038516\n",
      "[267,   100] loss : 0.039275\n",
      "[267,   200] loss : 0.039296\n",
      "[268,   100] loss : 0.038189\n",
      "[268,   200] loss : 0.038138\n",
      "[269,   100] loss : 0.038101\n",
      "[269,   200] loss : 0.037543\n",
      "[270,   100] loss : 0.037217\n",
      "[270,   200] loss : 0.038417\n",
      "[271,   100] loss : 0.038672\n",
      "[271,   200] loss : 0.037976\n",
      "[272,   100] loss : 0.038656\n",
      "[272,   200] loss : 0.038670\n",
      "[273,   100] loss : 0.038079\n",
      "[273,   200] loss : 0.038214\n",
      "[274,   100] loss : 0.038942\n",
      "[274,   200] loss : 0.037633\n",
      "[275,   100] loss : 0.036943\n",
      "[275,   200] loss : 0.039114\n",
      "[276,   100] loss : 0.038343\n",
      "[276,   200] loss : 0.040281\n",
      "[277,   100] loss : 0.043021\n",
      "[277,   200] loss : 0.042016\n",
      "[278,   100] loss : 0.038694\n",
      "[278,   200] loss : 0.039564\n",
      "[279,   100] loss : 0.038375\n",
      "[279,   200] loss : 0.038649\n",
      "[280,   100] loss : 0.038886\n",
      "[280,   200] loss : 0.037451\n",
      "[281,   100] loss : 0.036802\n",
      "[281,   200] loss : 0.038865\n",
      "[282,   100] loss : 0.038757\n",
      "[282,   200] loss : 0.038716\n",
      "[283,   100] loss : 0.038180\n",
      "[283,   200] loss : 0.038069\n",
      "[284,   100] loss : 0.037499\n",
      "[284,   200] loss : 0.038553\n",
      "[285,   100] loss : 0.038182\n",
      "[285,   200] loss : 0.037468\n",
      "[286,   100] loss : 0.037605\n",
      "[286,   200] loss : 0.038620\n",
      "[287,   100] loss : 0.038201\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[287,   200] loss : 0.037874\n",
      "[288,   100] loss : 0.037312\n",
      "[288,   200] loss : 0.038753\n",
      "[289,   100] loss : 0.037914\n",
      "[289,   200] loss : 0.039694\n",
      "[290,   100] loss : 0.038070\n",
      "[290,   200] loss : 0.037575\n",
      "[291,   100] loss : 0.038398\n",
      "[291,   200] loss : 0.041941\n",
      "[292,   100] loss : 0.040295\n",
      "[292,   200] loss : 0.039228\n",
      "[293,   100] loss : 0.038430\n",
      "[293,   200] loss : 0.038274\n",
      "[294,   100] loss : 0.037725\n",
      "[294,   200] loss : 0.037537\n",
      "[295,   100] loss : 0.037163\n",
      "[295,   200] loss : 0.037989\n",
      "[296,   100] loss : 0.038177\n",
      "[296,   200] loss : 0.038762\n",
      "[297,   100] loss : 0.037549\n",
      "[297,   200] loss : 0.038020\n",
      "[298,   100] loss : 0.037624\n",
      "[298,   200] loss : 0.038179\n",
      "[299,   100] loss : 0.037226\n",
      "[299,   200] loss : 0.037819\n",
      "[300,   100] loss : 0.037341\n",
      "[300,   200] loss : 0.038372\n",
      "[301,   100] loss : 0.038347\n",
      "[301,   200] loss : 0.039961\n",
      "[302,   100] loss : 0.038704\n",
      "[302,   200] loss : 0.037576\n",
      "[303,   100] loss : 0.039782\n",
      "[303,   200] loss : 0.036693\n",
      "[304,   100] loss : 0.038292\n",
      "[304,   200] loss : 0.038237\n",
      "[305,   100] loss : 0.038467\n",
      "[305,   200] loss : 0.037112\n",
      "[306,   100] loss : 0.037453\n",
      "[306,   200] loss : 0.037500\n",
      "[307,   100] loss : 0.038243\n",
      "[307,   200] loss : 0.038278\n",
      "[308,   100] loss : 0.037238\n",
      "[308,   200] loss : 0.038072\n",
      "[309,   100] loss : 0.037531\n",
      "[309,   200] loss : 0.038531\n",
      "[310,   100] loss : 0.037902\n",
      "[310,   200] loss : 0.037703\n",
      "[311,   100] loss : 0.038290\n",
      "[311,   200] loss : 0.039373\n",
      "[312,   100] loss : 0.038703\n",
      "[312,   200] loss : 0.039057\n",
      "[313,   100] loss : 0.038887\n",
      "[313,   200] loss : 0.038296\n",
      "[314,   100] loss : 0.039687\n",
      "[314,   200] loss : 0.037805\n",
      "[315,   100] loss : 0.038005\n",
      "[315,   200] loss : 0.039665\n",
      "[316,   100] loss : 0.037367\n",
      "[316,   200] loss : 0.038688\n",
      "[317,   100] loss : 0.038045\n",
      "[317,   200] loss : 0.037409\n",
      "[318,   100] loss : 0.036938\n",
      "[318,   200] loss : 0.038390\n",
      "[319,   100] loss : 0.038129\n",
      "[319,   200] loss : 0.038367\n",
      "[320,   100] loss : 0.037727\n",
      "[320,   200] loss : 0.038177\n",
      "[321,   100] loss : 0.037635\n",
      "[321,   200] loss : 0.037438\n",
      "[322,   100] loss : 0.036885\n",
      "[322,   200] loss : 0.037988\n",
      "[323,   100] loss : 0.038487\n",
      "[323,   200] loss : 0.037072\n",
      "[324,   100] loss : 0.038254\n",
      "[324,   200] loss : 0.037456\n",
      "[325,   100] loss : 0.038260\n",
      "[325,   200] loss : 0.038572\n",
      "[326,   100] loss : 0.037133\n",
      "[326,   200] loss : 0.037686\n",
      "[327,   100] loss : 0.037061\n",
      "[327,   200] loss : 0.038098\n",
      "[328,   100] loss : 0.038324\n",
      "[328,   200] loss : 0.037016\n",
      "[329,   100] loss : 0.037120\n",
      "[329,   200] loss : 0.038070\n",
      "[330,   100] loss : 0.037810\n",
      "[330,   200] loss : 0.036616\n",
      "[331,   100] loss : 0.037817\n",
      "[331,   200] loss : 0.037271\n",
      "[332,   100] loss : 0.036653\n",
      "[332,   200] loss : 0.038148\n",
      "[333,   100] loss : 0.038631\n",
      "[333,   200] loss : 0.036581\n",
      "[334,   100] loss : 0.037314\n",
      "[334,   200] loss : 0.036223\n",
      "[335,   100] loss : 0.036173\n",
      "[335,   200] loss : 0.038457\n",
      "[336,   100] loss : 0.038961\n",
      "[336,   200] loss : 0.039644\n",
      "[337,   100] loss : 0.039639\n",
      "[337,   200] loss : 0.039675\n",
      "[338,   100] loss : 0.037560\n",
      "[338,   200] loss : 0.037442\n",
      "[339,   100] loss : 0.037089\n",
      "[339,   200] loss : 0.036571\n",
      "[340,   100] loss : 0.038617\n",
      "[340,   200] loss : 0.036456\n",
      "[341,   100] loss : 0.036737\n",
      "[341,   200] loss : 0.037506\n",
      "[342,   100] loss : 0.037381\n",
      "[342,   200] loss : 0.036854\n",
      "[343,   100] loss : 0.037398\n",
      "[343,   200] loss : 0.036662\n",
      "[344,   100] loss : 0.038178\n",
      "[344,   200] loss : 0.036681\n",
      "[345,   100] loss : 0.037340\n",
      "[345,   200] loss : 0.036915\n",
      "[346,   100] loss : 0.037558\n",
      "[346,   200] loss : 0.038462\n",
      "[347,   100] loss : 0.039538\n",
      "[347,   200] loss : 0.036409\n",
      "[348,   100] loss : 0.037782\n",
      "[348,   200] loss : 0.037302\n",
      "[349,   100] loss : 0.038069\n",
      "[349,   200] loss : 0.037354\n",
      "[350,   100] loss : 0.038234\n",
      "[350,   200] loss : 0.036595\n",
      "[351,   100] loss : 0.036974\n",
      "[351,   200] loss : 0.037650\n",
      "[352,   100] loss : 0.036922\n",
      "[352,   200] loss : 0.037356\n",
      "[353,   100] loss : 0.036201\n",
      "[353,   200] loss : 0.037942\n",
      "[354,   100] loss : 0.037319\n",
      "[354,   200] loss : 0.036963\n",
      "[355,   100] loss : 0.036241\n",
      "[355,   200] loss : 0.036780\n",
      "[356,   100] loss : 0.037783\n",
      "[356,   200] loss : 0.036835\n",
      "[357,   100] loss : 0.037172\n",
      "[357,   200] loss : 0.037370\n",
      "[358,   100] loss : 0.039728\n",
      "[358,   200] loss : 0.040032\n",
      "[359,   100] loss : 0.038101\n",
      "[359,   200] loss : 0.036007\n",
      "[360,   100] loss : 0.036381\n",
      "[360,   200] loss : 0.036961\n",
      "[361,   100] loss : 0.035775\n",
      "[361,   200] loss : 0.038199\n",
      "[362,   100] loss : 0.036874\n",
      "[362,   200] loss : 0.037696\n",
      "[363,   100] loss : 0.036283\n",
      "[363,   200] loss : 0.037930\n",
      "[364,   100] loss : 0.036290\n",
      "[364,   200] loss : 0.038279\n",
      "[365,   100] loss : 0.037316\n",
      "[365,   200] loss : 0.036756\n",
      "[366,   100] loss : 0.037121\n",
      "[366,   200] loss : 0.037725\n",
      "[367,   100] loss : 0.037153\n",
      "[367,   200] loss : 0.037130\n",
      "[368,   100] loss : 0.037435\n",
      "[368,   200] loss : 0.036572\n",
      "[369,   100] loss : 0.037306\n",
      "[369,   200] loss : 0.040802\n",
      "[370,   100] loss : 0.038315\n",
      "[370,   200] loss : 0.037494\n",
      "[371,   100] loss : 0.038409\n",
      "[371,   200] loss : 0.036344\n",
      "[372,   100] loss : 0.035588\n",
      "[372,   200] loss : 0.037760\n",
      "[373,   100] loss : 0.037073\n",
      "[373,   200] loss : 0.037828\n",
      "[374,   100] loss : 0.037570\n",
      "[374,   200] loss : 0.036196\n",
      "[375,   100] loss : 0.037698\n",
      "[375,   200] loss : 0.038032\n",
      "[376,   100] loss : 0.037926\n",
      "[376,   200] loss : 0.036848\n",
      "[377,   100] loss : 0.037126\n",
      "[377,   200] loss : 0.037758\n",
      "[378,   100] loss : 0.037598\n",
      "[378,   200] loss : 0.036874\n",
      "[379,   100] loss : 0.035225\n",
      "[379,   200] loss : 0.038137\n",
      "[380,   100] loss : 0.036771\n",
      "[380,   200] loss : 0.036536\n",
      "[381,   100] loss : 0.036057\n",
      "[381,   200] loss : 0.037753\n",
      "[382,   100] loss : 0.036712\n",
      "[382,   200] loss : 0.036341\n",
      "[383,   100] loss : 0.035781\n",
      "[383,   200] loss : 0.037388\n",
      "[384,   100] loss : 0.036660\n",
      "[384,   200] loss : 0.036796\n",
      "[385,   100] loss : 0.035874\n",
      "[385,   200] loss : 0.036996\n",
      "[386,   100] loss : 0.036827\n",
      "[386,   200] loss : 0.038682\n",
      "[387,   100] loss : 0.037320\n",
      "[387,   200] loss : 0.036744\n",
      "[388,   100] loss : 0.037642\n",
      "[388,   200] loss : 0.034973\n",
      "[389,   100] loss : 0.036881\n",
      "[389,   200] loss : 0.036119\n",
      "[390,   100] loss : 0.037053\n",
      "[390,   200] loss : 0.036520\n",
      "[391,   100] loss : 0.035118\n",
      "[391,   200] loss : 0.037498\n",
      "[392,   100] loss : 0.035236\n",
      "[392,   200] loss : 0.037447\n",
      "[393,   100] loss : 0.037196\n",
      "[393,   200] loss : 0.038196\n",
      "[394,   100] loss : 0.036344\n",
      "[394,   200] loss : 0.037265\n",
      "[395,   100] loss : 0.038358\n",
      "[395,   200] loss : 0.038194\n",
      "[396,   100] loss : 0.038067\n",
      "[396,   200] loss : 0.035685\n",
      "[397,   100] loss : 0.037080\n",
      "[397,   200] loss : 0.036340\n",
      "[398,   100] loss : 0.037033\n",
      "[398,   200] loss : 0.036256\n",
      "[399,   100] loss : 0.035991\n",
      "[399,   200] loss : 0.036672\n",
      "[400,   100] loss : 0.036825\n",
      "[400,   200] loss : 0.036287\n",
      "[401,   100] loss : 0.035907\n",
      "[401,   200] loss : 0.037081\n",
      "[402,   100] loss : 0.036944\n",
      "[402,   200] loss : 0.035947\n",
      "[403,   100] loss : 0.035510\n",
      "[403,   200] loss : 0.037392\n",
      "[404,   100] loss : 0.035700\n",
      "[404,   200] loss : 0.037508\n",
      "[405,   100] loss : 0.036884\n",
      "[405,   200] loss : 0.036373\n",
      "[406,   100] loss : 0.037335\n",
      "[406,   200] loss : 0.035562\n",
      "[407,   100] loss : 0.035938\n",
      "[407,   200] loss : 0.036505\n",
      "[408,   100] loss : 0.036834\n",
      "[408,   200] loss : 0.037387\n",
      "[409,   100] loss : 0.036376\n",
      "[409,   200] loss : 0.037782\n",
      "[410,   100] loss : 0.037329\n",
      "[410,   200] loss : 0.036218\n",
      "[411,   100] loss : 0.036535\n",
      "[411,   200] loss : 0.035990\n",
      "[412,   100] loss : 0.036206\n",
      "[412,   200] loss : 0.037468\n",
      "[413,   100] loss : 0.036861\n",
      "[413,   200] loss : 0.037729\n",
      "[414,   100] loss : 0.041164\n",
      "[414,   200] loss : 0.037967\n",
      "[415,   100] loss : 0.036203\n",
      "[415,   200] loss : 0.036903\n",
      "[416,   100] loss : 0.036643\n",
      "[416,   200] loss : 0.036489\n",
      "[417,   100] loss : 0.035640\n",
      "[417,   200] loss : 0.036708\n",
      "[418,   100] loss : 0.036830\n",
      "[418,   200] loss : 0.035799\n",
      "[419,   100] loss : 0.036300\n",
      "[419,   200] loss : 0.035738\n",
      "[420,   100] loss : 0.036065\n",
      "[420,   200] loss : 0.035994\n",
      "[421,   100] loss : 0.036103\n",
      "[421,   200] loss : 0.036527\n",
      "[422,   100] loss : 0.035714\n",
      "[422,   200] loss : 0.036853\n",
      "[423,   100] loss : 0.036726\n",
      "[423,   200] loss : 0.036229\n",
      "[424,   100] loss : 0.037520\n",
      "[424,   200] loss : 0.036979\n",
      "[425,   100] loss : 0.036558\n",
      "[425,   200] loss : 0.036262\n",
      "[426,   100] loss : 0.036664\n",
      "[426,   200] loss : 0.036548\n",
      "[427,   100] loss : 0.038234\n",
      "[427,   200] loss : 0.037829\n",
      "[428,   100] loss : 0.036816\n",
      "[428,   200] loss : 0.038918\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[429,   100] loss : 0.037463\n",
      "[429,   200] loss : 0.036665\n",
      "[430,   100] loss : 0.036396\n",
      "[430,   200] loss : 0.035235\n",
      "[431,   100] loss : 0.035823\n",
      "[431,   200] loss : 0.036033\n",
      "[432,   100] loss : 0.036443\n",
      "[432,   200] loss : 0.035073\n",
      "[433,   100] loss : 0.035877\n",
      "[433,   200] loss : 0.036582\n",
      "[434,   100] loss : 0.035485\n",
      "[434,   200] loss : 0.035989\n",
      "[435,   100] loss : 0.036662\n",
      "[435,   200] loss : 0.038423\n",
      "[436,   100] loss : 0.036435\n",
      "[436,   200] loss : 0.035515\n",
      "[437,   100] loss : 0.037203\n",
      "[437,   200] loss : 0.034752\n",
      "[438,   100] loss : 0.035431\n",
      "[438,   200] loss : 0.035838\n",
      "[439,   100] loss : 0.035267\n",
      "[439,   200] loss : 0.036221\n",
      "[440,   100] loss : 0.036201\n",
      "[440,   200] loss : 0.036492\n",
      "[441,   100] loss : 0.037413\n",
      "[441,   200] loss : 0.040217\n",
      "[442,   100] loss : 0.036117\n",
      "[442,   200] loss : 0.036268\n",
      "[443,   100] loss : 0.036283\n",
      "[443,   200] loss : 0.035621\n",
      "[444,   100] loss : 0.035128\n",
      "[444,   200] loss : 0.037292\n",
      "[445,   100] loss : 0.036458\n",
      "[445,   200] loss : 0.036952\n",
      "[446,   100] loss : 0.036394\n",
      "[446,   200] loss : 0.036667\n",
      "[447,   100] loss : 0.036026\n",
      "[447,   200] loss : 0.035098\n",
      "[448,   100] loss : 0.035340\n",
      "[448,   200] loss : 0.036232\n",
      "[449,   100] loss : 0.036216\n",
      "[449,   200] loss : 0.035976\n",
      "[450,   100] loss : 0.035361\n",
      "[450,   200] loss : 0.036940\n",
      "[451,   100] loss : 0.036716\n",
      "[451,   200] loss : 0.036496\n",
      "[452,   100] loss : 0.035037\n",
      "[452,   200] loss : 0.037919\n",
      "[453,   100] loss : 0.035641\n",
      "[453,   200] loss : 0.036240\n",
      "[454,   100] loss : 0.035540\n",
      "[454,   200] loss : 0.035906\n",
      "[455,   100] loss : 0.036056\n",
      "[455,   200] loss : 0.035994\n",
      "[456,   100] loss : 0.037055\n",
      "[456,   200] loss : 0.034897\n",
      "[457,   100] loss : 0.035539\n",
      "[457,   200] loss : 0.035972\n",
      "[458,   100] loss : 0.034882\n",
      "[458,   200] loss : 0.036734\n",
      "[459,   100] loss : 0.036458\n",
      "[459,   200] loss : 0.041533\n",
      "[460,   100] loss : 0.037558\n",
      "[460,   200] loss : 0.040288\n",
      "[461,   100] loss : 0.036469\n",
      "[461,   200] loss : 0.036166\n",
      "[462,   100] loss : 0.034465\n",
      "[462,   200] loss : 0.037711\n",
      "[463,   100] loss : 0.034944\n",
      "[463,   200] loss : 0.036385\n",
      "[464,   100] loss : 0.034795\n",
      "[464,   200] loss : 0.036171\n",
      "[465,   100] loss : 0.035557\n",
      "[465,   200] loss : 0.035229\n",
      "[466,   100] loss : 0.035495\n",
      "[466,   200] loss : 0.034791\n",
      "[467,   100] loss : 0.034147\n",
      "[467,   200] loss : 0.036896\n",
      "[468,   100] loss : 0.036448\n",
      "[468,   200] loss : 0.034365\n",
      "[469,   100] loss : 0.036240\n",
      "[469,   200] loss : 0.035187\n",
      "[470,   100] loss : 0.035630\n",
      "[470,   200] loss : 0.037621\n",
      "[471,   100] loss : 0.037680\n",
      "[471,   200] loss : 0.035035\n",
      "[472,   100] loss : 0.035433\n",
      "[472,   200] loss : 0.036231\n",
      "[473,   100] loss : 0.038576\n",
      "[473,   200] loss : 0.036702\n",
      "[474,   100] loss : 0.036910\n",
      "[474,   200] loss : 0.036507\n",
      "[475,   100] loss : 0.034853\n",
      "[475,   200] loss : 0.038177\n",
      "[476,   100] loss : 0.035693\n",
      "[476,   200] loss : 0.038165\n",
      "[477,   100] loss : 0.035882\n",
      "[477,   200] loss : 0.035215\n",
      "[478,   100] loss : 0.035084\n",
      "[478,   200] loss : 0.036201\n",
      "[479,   100] loss : 0.035209\n",
      "[479,   200] loss : 0.036451\n",
      "[480,   100] loss : 0.036082\n",
      "[480,   200] loss : 0.035003\n",
      "[481,   100] loss : 0.034311\n",
      "[481,   200] loss : 0.035238\n",
      "[482,   100] loss : 0.036709\n",
      "[482,   200] loss : 0.035031\n",
      "[483,   100] loss : 0.036070\n",
      "[483,   200] loss : 0.034532\n",
      "[484,   100] loss : 0.034741\n",
      "[484,   200] loss : 0.036098\n",
      "[485,   100] loss : 0.033936\n",
      "[485,   200] loss : 0.036892\n",
      "[486,   100] loss : 0.033823\n",
      "[486,   200] loss : 0.036579\n",
      "[487,   100] loss : 0.035599\n",
      "[487,   200] loss : 0.035360\n",
      "[488,   100] loss : 0.035899\n",
      "[488,   200] loss : 0.035169\n",
      "[489,   100] loss : 0.034657\n",
      "[489,   200] loss : 0.036126\n",
      "[490,   100] loss : 0.035924\n",
      "[490,   200] loss : 0.034953\n",
      "[491,   100] loss : 0.039691\n",
      "[491,   200] loss : 0.037345\n",
      "[492,   100] loss : 0.037101\n",
      "[492,   200] loss : 0.038152\n",
      "[493,   100] loss : 0.035691\n",
      "[493,   200] loss : 0.035924\n",
      "[494,   100] loss : 0.035305\n",
      "[494,   200] loss : 0.036025\n",
      "[495,   100] loss : 0.035405\n",
      "[495,   200] loss : 0.034817\n",
      "[496,   100] loss : 0.035573\n",
      "[496,   200] loss : 0.034588\n",
      "[497,   100] loss : 0.035073\n",
      "[497,   200] loss : 0.035458\n",
      "[498,   100] loss : 0.035826\n",
      "[498,   200] loss : 0.035752\n",
      "[499,   100] loss : 0.034674\n",
      "[499,   200] loss : 0.036497\n",
      "[500,   100] loss : 0.034965\n",
      "[500,   200] loss : 0.035387\n",
      "Finished Training\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(500):\n",
    "    running_loss = 0.0\n",
    "    for i, data in enumerate(train_loader, 0):\n",
    "        # get the inputs: data is a list of [inputs, labels]\n",
    "        inputs, labels = data\n",
    "        #zero the parameter gradients\n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        #forward + backward + optimize\n",
    "        outputs,_ = model(inputs)\n",
    "        labels = labels.type(torch.LongTensor)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        # print statistics\n",
    "        running_loss += loss.item()\n",
    "        if (i+1) % 100 == 0:\n",
    "            print(\"[%d, %5d] loss : %f\" %\n",
    "                 (epoch+1, i+1, running_loss/2000))\n",
    "            running_loss = 0\n",
    "\n",
    "print(\"Finished Training\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca98103d",
   "metadata": {},
   "source": [
    "## Evaluate Train data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 280,
   "id": "c189911c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-273-a89117153749>:30: UserWarning: Implicit dimension choice for log_softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  a = self.log_softmax(z)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1925/2822\n",
      "Accuracy:  0.682\n"
     ]
    }
   ],
   "source": [
    "n_predict = 0\n",
    "n_correct = 0\n",
    "for data in train_loader:\n",
    "    inputs, labels = data\n",
    "    outputs,_ = model(inputs)\n",
    "    _, predicted = torch.max(outputs,1)\n",
    "\n",
    "    n_predict += len(predicted)\n",
    "    n_correct += (labels == predicted).sum()\n",
    "    \n",
    "print(f\"{n_correct}/{n_predict}\")\n",
    "print(f\"Accuracy: {n_correct/n_predict: .3f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 285,
   "id": "38c7c1f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = torch.load(\"./model/model.pt\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2101ac2e",
   "metadata": {},
   "source": [
    "## Evaluate Test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 286,
   "id": "5129fe6c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-273-a89117153749>:30: UserWarning: Implicit dimension choice for log_softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  a = self.log_softmax(z)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "385/706\n",
      "Accuracy:  0.545\n"
     ]
    }
   ],
   "source": [
    "n_predict = 0\n",
    "n_correct = 0\n",
    "for data in test_loader:\n",
    "    inputs, labels = data\n",
    "    outputs,_ = model(inputs)\n",
    "    _, predicted = torch.max(outputs,1)\n",
    "\n",
    "    n_predict += len(predicted)\n",
    "    n_correct += (labels == predicted).sum()\n",
    "    \n",
    "print(f\"{n_correct}/{n_predict}\")\n",
    "print(f\"Accuracy: {n_correct/n_predict: .3f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "702f5698",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32ab387c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "raw",
   "id": "94d38b7c",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "528e3fdb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "f63770a8",
   "metadata": {},
   "source": [
    "## Save Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 259,
   "id": "157de5f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "if not os.path.isdir(\"./model\") :\n",
    "    os.mkdir(\"./model\")\n",
    "torch.save(model,\"./model/model.pt\") ## prac - 0.554 , test - 0.545"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 267,
   "id": "4e3b5c85",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(model,\"./model/model1.pt\") ## prac - 0.566 , test - 0.545, epoch 100,layer : [256,128,64,32] , lr = 0.0005,weight_decay = 1e-5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 278,
   "id": "60afae0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(model,\"./model/model2.pt\") ## prac - 0.600, test - 0.520, epcoh : 500, layer :[512,256,128,64,32], lr = 0.0001, weight_decay = 1e-5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04040707",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
